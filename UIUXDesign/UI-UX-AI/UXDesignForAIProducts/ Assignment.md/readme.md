# Assignment

<details>
  <summary>1. Propose a Design Concept for an AI-Powered Interactive Product</summary>

### Instructions:
- Identify a specific human need or gap and imagine an AI product that can address it.
- Describe what the product would look like if it were designed to completely replace human effort, and explain why this design might be rejected or fail.
- Then, outline an alternative design focusing on intelligence augmentation, where the AI assists humans rather than replaces them, and explain why this augmented approach might succeed where the fully automated version could fail. 
</details>

<details>
  <summary>2. Prototyping with AI</summary>

### Instructions:
- In this activity, you will explore how AI can assist with a specific task in your organization by using a large language model (LLM) like ChatGPT.
- You will create a simple prototype that demonstrates how AI can process structured inputs and outputs, focusing on short text or numerical data.  
 
### Guidelines for this assignment: 
- **1.Identify a Task** - Think of a specific task where AI could be helpful for you or your organization. Ensure that this task involves structured inputs and outputs, focusing on short text or numbers. For example, consider tasks like summarizing feedback, generating reports, or classifying data.  
- **2.Create a ChatGPT Account** - If you do not already have an account, go to the ChatGPT website and create one. This will allow you to access the model and start experimenting. 
- **3.Develop Your Prompt** - Write a clear prompt that describes what you want the AI to do. Include specific examples to illustrate how the AI should respond. Here is a template to follow:  

Prompt Structure:  
- If I tell you [input], it should produce [expected output].  
- If I tell you [another input], it should produce [another expected output].  
 
This is an example of how the prompt structure should look:  
- If I tell you "The weather is sunny," it should produce "It's a great day for outdoor activities!"  
- If I tell you "The sales increased by 20%," it should produce "Sales performance is strong this quarter."  
 
- **4. Test the AI** - Input various examples into ChatGPT based on your prompt and observe the outputs. Evaluate how well the AI performs the task you designed.  

- **5. Iterate on Your Prompt** - Based on the AI's responses, refine your prompt to improve the accuracy and relevance of the outputs. Experiment with different phrasings or examples to see how the AI's performance changes.  

After your testing and iterations, reflect on the following questions:  
- How close did you get to a technical prototype?  
- How well did the AI perform the task you designed?  
- What adjustments did you make to improve the AI's responses?  
 
This activity will help you understand the potential of AI in your work and how to effectively communicate tasks to an AI model.  
</details>
---
<details>
  <summary>3. Exploring Designs for an AI-Powered System</summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

###b Instructions
- Choose a potential AI-powered system (this can be a made-up or existing idea) and explore three parallel designs for it using different design patterns or strategies (e.g., as an interface agent, direct manipulation, mixed-initiative interaction, prompting, accelerator, verifier, design gallery).
- Include rough sketches of how the interface might look or behave.
- After evaluating each option: which one do you think would be the best fit?
- Why? 
</details>

<details>
  <summary>4. Cases of Overreliance and Algorithm Aversion </summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

### Instructions
- For this assignment, you will search and identify one case of overreliance and one case of algorithm aversion when using generative AI.
- For each case, mention how you recognized that behavior, why users acted that way, and how it could have been avoided. 
</details>

<details>
  <summary>5. Designing an AI Chatbot Interface</summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

### Instructions 

In this assignment, you will design a chatbot interface for an AI-powered product of your choice.
This will give you the chance to explore chatbot design, consider user psychology, and think through the interactions users might have with the chatbot. 
 
**Guidelines for this assignment: **
- 1. Select an AI-powered product (e.g., virtual assistant, customer service bot) and imagine how it would use a chatbot interface. 
- 2. Create simple wireflows (sketches of user interactions) that address the following considerations: 

- User entry points: How users start a conversation with the bot 
- Conversational flow: The back-and-forth dialogue between user and bot, including different paths the conversation might take 
- Human responses: Design your wireflows with the understanding that users may respond to the chatbot as if it were human. Focus on creating natural interactions that build trust and engagement. 
 
Deliverables: 
- A brief description of the AI-powered product and how/why a chatbot would improve it. 
- Your wireflows (sketches) showing the chatbot’s design and dialogue trees 
- A short reflection on how you accounted for the variety of potential interactions with users 
</details>

<details>
  <summary>Creating a Simple Generative Agent</summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

### Instructions 
- For this assignment, you will create a simple generative agent using GPT or a similar model.
- Prompt that agent with different situations and scenarios and see how the agent reacts.
- Does it make reasonable decisions?
- Why or why not?
- Does the quality of the agent’s decisions improve when you adjust the prompt you provide the LLM with? 

Example:
- **Sample persona description for the LLM:**
"Michael Bernstein is a faculty member in the Computer Science Department at Stanford University. He focuses
in the area of human-computer interaction. He's a high-energy, jovial, and focused person, and he cares deeply
about creating technology that helps people and brings delight—not tech for its own sake. To do so, he draws
deeply on the social and behavioral sciences, then connects those insights with interaction design. He grew up
and lives in California. He will never say no to chicken soup, no matter the temperature outside.”
- **Prompts for the LLM:**
“Task: What you see above is a brief description of a persona. Based on that description, please predict
that persona's responses to the survey question or situation below. If the survey options or situation are
multiple choice, you must guess from one of the options presented.”
Situation and survey questions for the LLM:
“Survey questions: Which class would this persona rather take? (1) Advanced topics in computer
networking (2) Political sociology?"
</details>
---
<details>
  <summary>Black Mirror Writers Room</summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

### Instructions 
- For this assignment, you will have to explore the ethical implications of a chosen technology.
- Create a “Black Mirror”-style scenario that highlights an ethical dilemma.
- The aim of this exercise is to critically evaluate the potential future impacts of your technology by imagining a cautionary tale that amplifies the anxieties and issues it may create.
- This will help you shape your design to mitigate potential negative outcomes.  
 
- 1. Brainstorm future technology: Think about the technology or product you are currently designing. Imagine a near-future version of this technology, envisioning what it might look like in 5 or 10 years if it succeeds. Describe this future technology in detail.  
- 2. Identify anxieties and issues: Consider the potential anxieties and issues that your future technology might create. Reflect on how it might affect  individuals and society. Examples include job displacement, loss of autonomy, privacy concerns, and social disapproval. List these anxieties and issues.  
- 3. Character and story: Identify a fictional character who best illustrates the cautionary tale, describing this person and their story. How do they interact with the future technology? What challenges and issues do they face because of it?  
- 4. Ethics and society review: Once everything is ready, conduct an ethics and society review of your current design. Consider the ethical principles and societal impacts discussed above. Make any adjustments needed in your design process to ensure ethical and responsible development.  

By completing this exercise, you will gain a deeper understanding of the potential ethical impacts of this technology and learn how to proactively address these issues in your design process.  
</details>

<details>
  <summary>Ethics and Society Review</summary>

This assignment is mandatory and will therefore be evaluated as part of your final grade. This assignment must be completed individually. 

### Instructions
- In this assignment, you are tasked with conducting an Ethics and Societal Review of a product that you use or work with.
- This review should critically evaluate the ethical challenges and potential negative societal risks associated with the product and propose strategies to mitigate these issues.  
 
### Guidelines for this assignment: 

#### 1. Product selection:
- Identify a specific product that you either use personally or work with.
- This product can be technological, digital, or otherwise relevant to your field of study.
Ensure that you can access sufficient information about this product to conduct a thorough review.  

#### 2. Ethical and societal risks:
- For the chosen product, describe the ethical challenges and potential negative societal risks that could arise once the product is commercialized or widely used.
- Consider the implications of the product's deployment outside your direct control.
- For example, reflect on how the product might be misused or lead to unintended consequences.  

#### 3. Mitigation principles:
- Identify and explain the principles that should guide professionals in your field to mitigate the identified risks.
- These principles should address the core ethical concerns associated with the product and provide a framework for ensuring responsible development and use.
- Below is a table that outlines examples of potential risks, associated principles, and strategies for mitigating these risks.
This table serves as a reference to help you identify and address similar concerns in your own product analysis. 
---
- **Risk** - **Representativeness**. Insufficient or unequal representation of data, participants, or intended user population. Example: data collection process for a wellbeing sensing algorithm would under-sample low-income populations  
- **Example Principle** - Algorithm training data and evaluation should include communities likely to be impacted by the algorithm  	
- **Example Mitigation** - Commitment to explicitly recruit low-income individuals to ensure that their data is included in the training, and that their voices are heard in the evaluation
---
- **Risk** - **Diverse design and deployment**. Incorporating relevant stakeholders and diverse perspectives in the project design and deployment process. Example: an algorithm for fairer school choice does not consider the voice of those historically disadvantaged by school choice mechanisms  
- **Example Principle** - Algorithms for social choice should directly consult with stakeholders who would be impacted by their deployment	
Commitment to include a PI on the project who brings expertise on experiences in education from historically disadvantaged groups  
- **Example Mitigation** - Commitment that the researchers will engage in stakeholder discussions or participatory design processes with members of historically disadvantaged groups
---
- **Risk** - **Dual use**.The technology being co-opted for nefarious purposes or by motivated actors. Example: algorithmic sensing advances might be co-opted by authoritarian governments or employers for surveillance  
- **Example Principle** - Sensing algorithms should place control in the hands of those being sensed  	
Commitment to develop an architecture where the sensing algorithm operates on the user's device and keeps all data local  
- **Example Mitigation** - Commitment to use the "bully pulpit" of Stanford researchers to describe the importance of this architecture in papers and talks about the research  
---
- **Risk** - **Harms to subgroups**. Harms to populations that could arise following from the research's success or translation into policy.Example: teacher job loss due to better education algorithms  
- **Example Principle** - Educational interventions should be designed as amplifying teachers' abilities, rather than replacing teachers	- **Example Mitigation** - Commitment to designing the algorithm in a way that requires teacher input and oversight  
---

### 4. Design and implementation
- Describe concrete ways in which these principles can be integrated into the design and operational processes of the product.
- Specify the commitments and measures that would be taken to adhere to these principles.
- For example, outline any design choices, policies, or practices that would be implemented to reduce the risk of misuse or harm.  
 
In your response, aim to provide a comprehensive and well-organized analysis of the ethical and societal implications of the product. Your discussion should not only highlight potential risks but also demonstrate how proactive measures can address these concerns effectively. 

Please submit your completed assignment with a clear exposition of the risks, principles, and mitigation strategies as they apply to your selected product.
</details>