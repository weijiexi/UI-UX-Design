#  Module 5: Designing Social AIs: Chatbots
we will explore AI chatbots that mimic human behavior, and how they have become social actors in relation to human beings. In this context, it is essential to understand what makes chatbots effective, why they evoke human-like responses, and how to manage the changing landscape of AI-human interaction. Let’s dive into what works, what doesn’t, and how to create more engaging and responsible AI experiences.
- Articulate the design space of social chatbots
- Explain how and why our human psychological hardware causes us to react to AI chatbots as if they were other humans
- Understand the risks of AI-generated content that is nearly indistinguishable from humans

**Anthropomorphic/anthropomorphize**: treating animals or objects as if they were human in their appearance, behavior and personality.    
**Conceptual metaphors**: Ways of explaining new or complex ideas by comparing them to everyday people and things.  
**Dialogue trees**: Branching narrative structures used in conversations with AI chatbot interfaces, where the user's responses lead to different paths and outcomes.  Designers can use these to map out the potential flow of a conversation and the ways it can progress based on user input.  
**Pattern matching**: The process of finding and recognizing repeated patterns in data, which helps computers perform tasks like allowing large language models to predict and generate text.  
**Replicant Effect**: In a system where AIs and humans co-exist, people are less likely to trust anything produced by AI, especially if it’s unclear what is AI-generated and what is written by humans  
**The Media Equation**: a theory proposing that people respond to computers and other technologies, in the same ways that they respond to other people.  
**The Uncanny Valley**: a theory suggesting that highly realistic, but not perfectly human-like AI systems and robots can elicit feelings of unease or even revulsion in users  

<details>
  <summary>1. The AI Chatbot Rogues’ Gallery</summary>

  When we refer to chatbots, we are talking about a broad category of interfaces that take on human characteristics when they communicate, most commonly via natural language.

  ### **The Architecture Behind Social Chatbots**
  At a high level, if these models generate open-ended responses dynamically rather than from a pre-written script, **it is typically a large language model behind the scenes, fine-tuned on human feedback**.
  - Generative Agents
  - AI Influencers and Performers
  - Customer Support Bots

  ### **Dialogue trees** 
  Dialogue trees function like **flowcharts** that map out potential conversation paths (resembling the branches of a tree). Each tree is composed of nodes that represent questions, responses, or actions. Each node represents decisions or user input, leading to branches that determine how the bot will respond.
  - Health Support Bots
  - Pick Your Metaphor Carefully

  ### **Pick Your Metaphor Carefully**
  Conceptual metaphors are vital tools for designers, shaping users’ expectations of the AI chatbot they are about to engage with.

  When AI agents were presented using metaphors that suggested a low level of competence (e.g., a toddler), users were more likely to judge the chatbots positively than if they had been described using a metaphor that suggested a high level of competence (e.g., a trained professional).

  users' intentions of adopting the AI system were higher when an AI’s perceived competence was lower.

  we realized that even if a high-competence AI completed its tasks well, users who were promised anything more than an encounter with an AI toddler would be reluctant to cooperate and were far less forgiving of mistakes. And this wasn't just because the AI wasn't able to follow through on its promises! In all cases, the AI was actually powered by an expert human behind the scenes—so there weren't any errors. Even a perfect chatbot isn't perfect enough; people will judge it.

  This demonstrates the importance of using the right metaphor when presenting a new AI system or next-generation AI to your user base. It could mean either a satisfied user base or one that abandons your product in droves.

  [Conceptual Metaphors Impact Perceptions of Human-AI Collaboration](https://drive.google.com/file/d/1g3SvTnCEYLKEE1k3yzLO7psqyuWs7U-t/view?usp=sharing)

</details>

<details>
  <summary>2. How AIs Integrate as Social Actors</summary>

  ### **The Media Equation**
  The Media Equation proposes that people automatically react to computers and (by extension, AI systems) as if they were people.

  ### **The Uncanny Valley**
  The Uncanny Valley is a concept that originated in the robotics field, describing the relationship between an object’s resemblance to a human being and its likeability. It hypothesizes that people initially develop a higher level of affinity for an object as it begins to resemble the human form (e.g. a toy robot). However, at a certain point, when the humanlike simulation becomes just a little too accurate or lifelike, people begin to find the object strange and disconcerting.

  From a design perspective, the key to escaping from the uncanny valley (or to sidestep it altogether) is to consider adopting a weaker level of human likeness or avoiding using a humanlike design altogether. For example, when Microsoft envisioned its smart assistant Cortana in the Halo video games, she was a high-fidelity female-presenting AI bot. But, when Microsoft launched the Cortana smart assistant as part of its Windows operating system, developers moved away from a high-fidelity representation and turned Cortana into an abstract pulsing circle, much like Siri and ChatGPT.

  [The Uncanny Valley: The Original Essay by Masahiro Mori](https://spectrum.ieee.org/the-uncanny-valley)

</details>

<details>
  <summary>3. AI Influences Our Social Interactions With Each Other</summary>

  ### **The Replicant Effect**

  The Replicant Effect becomes difficult to tell the difference between AI-generated and human-created content. 

  [Generative AI and the End of Trust](https://www.youtube.com/watch?v=XUCUNvu8QUg)


</details>