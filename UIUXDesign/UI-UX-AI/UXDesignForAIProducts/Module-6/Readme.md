# Module 6: Generative Agents: Simulating Human Behavior

## Core Concepts
- **Generative Agents**: AI-driven entities simulating believable (not necessarily accurate) human behavior through language models.
- **Soar Architecture**: Cognitive model integrating human-like processes (learning, memory, decision-making).
- **Memory Stream**: Chronological log of agent experiences used to retrieve relevant information.
- **Ackerman’s Socio-Technical Gap**: The disconnect between social needs and what current tech can support.

## Why Simulate Human Behavior?
- **Thomas Schelling’s Micromotives and Macrobehavior** shows how small personal preferences can create large social patterns (e.g., segregation).
- AI behavior simulations help predict user responses, test policies, or rehearse conversations (e.g., conflict with manager).
- Simulations can detect unintended consequences, second-order effects, and support user-centered design.

## LLMs + Human Simulation
- **LLMs** (e.g., ChatGPT) can simulate personas based on internet-trained behavior.
- Agents can now reflect, plan, interact, and respond without pre-coded scripts.
- **Stanford’s “Smallville” simulation** illustrates how 25 generative agents autonomously live, remember, plan, and interact believably.

## Architecture of Generative Agents
- **Memory**: Filtered by recency, relevance, importance.
- **Reflection**: Agents infer patterns from past experiences.
- **Planning**: Daily behavior plans based on context and memory.

## Design Risks
- Hallucinations or memory failure reduce believability.
- Overly formal, unnatural dialogue due to training data.
- Over-cooperation from LLM instruction tuning.

## Applications & Design Implications
- Use simulations to test designs, social features, or policy impacts before launch.
- Important in HCI, UX, organizational design, and public policy.
- Helps bridge the **socio-technical gap** with more accurate behavioral forecasting.

## Looking Forward
- Shift from **believability → accuracy**
- Scale models from 25 to 25 million agents
- Defend against prompt injection with better memory and context modeling
- Empower human decision-making by building socially responsive tools
