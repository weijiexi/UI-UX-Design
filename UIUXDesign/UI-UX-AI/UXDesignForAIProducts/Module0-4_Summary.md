# Module 0ï½ž4 Review Summary

## Module 0: Introduction to AI Design
Module 0 introduces the purpose of the course: designing user-centered AI systems. It frames AI design as requiring an understanding of both human needs and AI capabilities. Students are encouraged to explore responsible, human-centered approaches and to prototype ideas rapidly using tools like LLMs. The module sets the stage for thinking about AI's role in augmenting human work rather than replacing it.

## Module 1: Understanding AI Design Patterns
Module 1 covers foundational AI design patterns. These include:
- **Interface Agents**: AI that acts autonomously for the user
- **Direct Manipulation**: Human retains full control
- **Mixed-Initiative Interaction**: Shared task flow between AI and human
- **Accelerators**: Auto-suggestions or quick completions (e.g. autocomplete)
- **Verifiers**: AI flags possible errors for user confirmation
- **Design Galleries**: AI shows multiple creative options for selection
These patterns form the vocabulary of designing AI user experiences.

## Module 2: Prototyping AI Systems
Module 2 dives into AI prototyping. It distinguishes between:
- **Experience Prototypes** (simulate interaction)
- **Technical Prototypes** (test feasibility)
- **Wizard of Oz** (human simulates AI)
- **LLM-Based Prototypes** (rapid prototyping using ChatGPT, Claude, etc.)

The module introduces the two phases of AI prototyping: product vision and model development. It emphasizes iterative design to test both usability and technical viability early in the process.

## Module 3: User Control vs. Automation
Module 3 addresses the balance between automation and user control. It explores the pros and cons of:
- **Direct Manipulation vs. Interface Agents**
- **Mixed-Initiative Systems** (dynamic handoff based on AI confidence)
- **Agency + Automation** (high automation without removing human control)

It also introduces design patterns like:
- **Accelerators** (autocomplete)
- **Verifiers** (error checking)
- **Design Galleries** (multiple AI outputs)
Designers must choose and blend these patterns to align with task complexity, user goals, and risk levels.

## Module 4: User Trust and Explainability
Module 4 centers on user trust and explainability in AI systems. It highlights two challenges:
- **Algorithm Aversion** (loss of trust after errors)
- **Overreliance** (blindly trusting AI suggestions)

Solutions explored include:
- **Complementarity** (AI and human collaboration outperform either alone)
- **Explainability Techniques**:
   - Commonsense Reasoning
   - Feature Attribution (e.g. Shapley values)
   - LIME (local surrogate models)
   - Mechanistic Interpretability (neuron activation patterns)
- **The Explainability Dilemma**: trade-off between technical accuracy and user understanding
The goal is designing systems that are transparent, trustworthy, and effectively augment human decision-making.

